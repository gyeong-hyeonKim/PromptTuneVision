import os
import sys
import re
import datetime # ì‹œê°„ ë¡œê¹…ì„ ìœ„í•´ ì¶”ê°€
import subprocess # Streamlit ì‹¤í–‰ì„ ìœ„í•´ ì¶”ê°€
import argparse # __main__ ë¸”ë¡ì—ì„œ ì¸ì íŒŒì‹±ì„ ìœ„í•´ argparseë¥¼ ì—¬ê¸°ì—ë„ import

# --- ë””ë²„ê¹… ë¡œê·¸ í•¨ìˆ˜ ---
def log_message(message):
    print(f"[{datetime.datetime.now()}] RUN_PIPELINE_DEBUG: {message}", flush=True)

log_message("ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ì ")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
log_message(f"BASE_DIR: {BASE_DIR}")
SCRIPT_PATH = os.path.join(BASE_DIR, "scripts")
log_message(f"SCRIPT_PATH: {SCRIPT_PATH}")
FRAME_PATH = os.path.join(SCRIPT_PATH, "Frame")
log_message(f"FRAME_PATH: {FRAME_PATH}")

sys.path.append(SCRIPT_PATH)
log_message(f"sys.pathì— SCRIPT_PATH ì¶”ê°€: {SCRIPT_PATH}")
sys.path.append(FRAME_PATH)
log_message(f"sys.pathì— FRAME_PATH ì¶”ê°€: {FRAME_PATH}")

log_message("Frame_Extraction import ì‹œë„")
from Frame_Extraction import extract_frames
log_message("Frame_Extraction import ì™„ë£Œ")

log_message("CLIP_Similarity import ì‹œë„")
from CLIP_Similarity import load_prompt, load_frames as load_clip_frames, compute_clip_similarity, save_results as save_clip_results
log_message("CLIP_Similarity import ì™„ë£Œ")

log_message("YOLO_Detection import ì‹œë„")
from YOLO_Detection import load_frames as load_yolo_frames, detect_objects, save_results as save_yolo_results
log_message("YOLO_Detection import ì™„ë£Œ")

log_message("Object_Comparison import ì‹œë„")
from Object_Comparison import extract_keywords_from_prompt, load_yolo_results, compare_objects, save_results as save_comparison_results
log_message("Object_Comparison import ì™„ë£Œ")

log_message("Generate_Feedback_API import ì‹œë„")
from Generate_Feedback_API import load_context as load_context_feedback, generate_prompt, call_gpt as call_feedback_gpt, save_feedback
log_message("Generate_Feedback_API import ì™„ë£Œ")

log_message("Generate_Improved_prompt_API import ì‹œë„")
from Generate_Improved_prompt_API import load_context as load_context_prompt, create_prompt, call_gpt as call_improved_gpt, save_output
log_message("Generate_Improved_prompt_API import ì™„ë£Œ")

log_message("ëª¨ë“  ëª¨ë“ˆ import ì™„ë£Œ")


def run_pipeline(prompt_path, video_path, model_path="yolov8m.pt"):
    log_message(f"run_pipeline í•¨ìˆ˜ ì‹œì‘. prompt_path='{prompt_path}', video_path='{video_path}'")

    prompt_filename = os.path.basename(prompt_path)
    log_message(f"prompt_filename: '{prompt_filename}'")

    match = re.search(r"(\d{8}_\d{6})", prompt_filename)
    if not match:
        time_based_foldername = os.path.splitext(prompt_filename)[0]
        log_message(f"[ê²½ê³ ] ì‹œê°„ ì •ë³´ ëª» ì°¾ìŒ. time_based_foldername ì„¤ì •: '{time_based_foldername}'")
    else:
        time_based_foldername = match.group(1)
        log_message(f"ì‹œê°„ ì •ë³´ ì°¾ìŒ. time_based_foldername ì„¤ì •: '{time_based_foldername}'")

    video_name_for_files = os.path.splitext(os.path.basename(video_path))[0] # ê²°ê³¼ íŒŒì¼ëª…ì— ì‚¬ìš©ë  ë¹„ë””ì˜¤ ì´ë¦„
    log_message(f"video_name_for_files: '{video_name_for_files}'")
    project_base_path = os.path.abspath(os.path.dirname(__file__)) # run_pipeline.py ìœ„ì¹˜
    log_message(f"project_base_path: '{project_base_path}'")

    main_output_dir = os.path.join(project_base_path, "data", time_based_foldername)
    log_message(f"main_output_dir ê²½ë¡œ ì •ì˜: '{main_output_dir}'")
    os.makedirs(main_output_dir, exist_ok=True)
    log_message(f"main_output_dir ìƒì„± ì™„ë£Œ (ë˜ëŠ” ì´ë¯¸ ì¡´ì¬).")

    frame_output_dir = os.path.join(main_output_dir, "frames", video_name_for_files)
    log_message(f"frame_output_dir ê²½ë¡œ ì •ì˜: '{frame_output_dir}'")

    analysis_result_dir = os.path.join(main_output_dir, "analysis_results")
    log_message(f"analysis_result_dir ê²½ë¡œ ì •ì˜: '{analysis_result_dir}'")
    os.makedirs(analysis_result_dir, exist_ok=True)
    log_message(f"analysis_result_dir ìƒì„± ì™„ë£Œ (ë˜ëŠ” ì´ë¯¸ ì¡´ì¬).")

    print(f"\n[INFO] ëª¨ë“  ê²°ê³¼ëŠ” '{main_output_dir}' í´ë” í•˜ìœ„ì— ì €ì¥ë©ë‹ˆë‹¤.")
    log_message("ê¸°ë³¸ INFO ë©”ì‹œì§€ ì¶œë ¥ ì™„ë£Œ")

    print("\n[1ï¸âƒ£] í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘")
    log_message(f"extract_frames í˜¸ì¶œ ì§ì „. video_path='{video_path}', frame_output_dir='{frame_output_dir}'")
    extract_frames(video_path, frame_output_dir, frame_interval=10)
    log_message("extract_frames í˜¸ì¶œ ì™„ë£Œ")

    print("\n[2ï¸âƒ£] CLIP ìœ ì‚¬ë„ ë¶„ì„ ì‹œì‘")
    # (ì´í•˜ CLIP, YOLO, ê°ì²´ ë¹„êµ, GPT í”¼ë“œë°±, GPT ê°œì„  í”„ë¡¬í”„íŠ¸ ìƒì„± ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
    # ... (ëª¨ë“  ë¶„ì„ ë° íŒŒì¼ ì €ì¥ ë¡œì§) ...
    prompt = load_prompt(prompt_path)
    clip_frame_paths = load_clip_frames(frame_output_dir)
    clip_scores = compute_clip_similarity(prompt, clip_frame_paths, device="cuda")
    clip_json_path = os.path.join(analysis_result_dir, f"{video_name_for_files}_clip.json")
    clip_plot_path = os.path.join(analysis_result_dir, f"{video_name_for_files}_clip_plot.png")
    save_clip_results(clip_scores, clip_json_path, clip_plot_path)
    log_message("CLIP ë¶„ì„ ë° ì €ì¥ ì™„ë£Œ")

    print("\n[3ï¸âƒ£] YOLO ê°ì²´ íƒì§€ ì‹œì‘")
    yolo_frame_paths = load_yolo_frames(frame_output_dir)
    yolo_results = detect_objects(model_path, yolo_frame_paths, device="cuda")
    yolo_json_path = os.path.join(analysis_result_dir, f"{video_name_for_files}_yolo.json")
    save_yolo_results(yolo_results, yolo_json_path)
    log_message("YOLO íƒì§€ ë° ì €ì¥ ì™„ë£Œ")

    print("\n[4ï¸âƒ£] ê°ì²´ ë¹„êµ ìˆ˜í–‰")
    with open(prompt_path, "r", encoding="utf-8") as f:
        prompt_text = f.read()
    prompt_objects = extract_keywords_from_prompt(prompt_text)
    detected_objects = load_yolo_results(yolo_json_path)
    comparison_result = compare_objects(prompt_objects, detected_objects)
    comparison_path = os.path.join(analysis_result_dir, f"{video_name_for_files}_object_comparison.json")
    save_comparison_results(comparison_result, comparison_path)
    log_message("ê°ì²´ ë¹„êµ ë° ì €ì¥ ì™„ë£Œ")

    print("\n[5ï¸âƒ£] GPT í”¼ë“œë°± ìƒì„±")
    context = load_context_feedback(comparison_path)
    feedback_prompt_text = generate_prompt(context) # generate_prompt í•¨ìˆ˜ëŠ” feedback_promptë¡œ ì´ë¦„ì„ ë³€ê²½í–ˆì—ˆëŠ”ì§€ í™•ì¸ í•„ìš”
    feedback = call_feedback_gpt(feedback_prompt_text)
    feedback_path = os.path.join(analysis_result_dir, f"{video_name_for_files}_feedback_gpt.txt")
    save_feedback(feedback, feedback_path)
    log_message("GPT í”¼ë“œë°± ìƒì„± ë° ì €ì¥ ì™„ë£Œ")

    print("\n[6ï¸âƒ£] GPT ê°œì„  í”„ë¡¬í”„íŠ¸ ìƒì„±")
    prompt_context = load_context_prompt(prompt_path, comparison_path)
    improved_prompt_text_for_gpt = create_prompt(prompt_context) # create_prompt í•¨ìˆ˜ëŠ” improved_prompt_textë¡œ ì´ë¦„ì„ ë³€ê²½í–ˆì—ˆëŠ”ì§€ í™•ì¸ í•„ìš”
    improved_prompt_output = call_improved_gpt(improved_prompt_text_for_gpt)
    improved_prompt_path = os.path.join(analysis_result_dir, f"{video_name_for_files}_feedback_and_revised_prompt.txt")
    save_output(improved_prompt_output, improved_prompt_path)
    log_message("GPT ê°œì„  í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì €ì¥ ì™„ë£Œ")
    
    print("\n[âœ…] ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    log_message("run_pipeline í•¨ìˆ˜ ë‚´ ë¶„ì„ ë¡œì§ ì •ìƒ ì¢…ë£Œ")

    #  streamlit_app.pyì˜ ì ˆëŒ€ ê²½ë¡œ (run_pipeline.pyì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆë‹¤ê³  ê°€ì •)
    streamlit_app_script_path = os.path.join(project_base_path, "streamlit_app.py")

    # Streamlit ì•± ì‹¤í–‰ì— í•„ìš”í•œ ì¸ìë“¤ì„ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    abs_analysis_result_dir = os.path.abspath(analysis_result_dir)
    abs_prompt_path = os.path.abspath(prompt_path)
    abs_video_path = os.path.abspath(video_path)

    # Streamlit ì‹¤í–‰ ëª…ë ¹ì–´ êµ¬ì„±
    # sys.executableì€ í˜„ì¬ íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„°ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    streamlit_command = [
        sys.executable, "-m", "streamlit", "run", streamlit_app_script_path,
        "--", # Streamlit ìì²´ ì¸ìì™€ ìŠ¤í¬ë¦½íŠ¸ ì¸ì êµ¬ë¶„
        "--results_dir", abs_analysis_result_dir,
        "--prompt_file_path", abs_prompt_path,
        "--video_file_path", abs_video_path,
        "--video_name", video_name_for_files # í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª…ì´ ì•„ë‹Œ, ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ ì´ë¦„ ì‚¬ìš©
    ]

    print(f"\n[ğŸš€] Streamlit ëŒ€ì‹œë³´ë“œ ì‹¤í–‰: {' '.join(streamlit_command)}")
    log_message(f"Streamlit ì•± ì‹¤í–‰ ì‹œë„: {' '.join(streamlit_command)}")
    
    # Popenì„ ì‚¬ìš©í•˜ì—¬ Streamlitì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ (run_pipeline.py ì¢…ë£Œ í›„ì—ë„ ìœ ì§€)
    try:
        subprocess.Popen(streamlit_command)
        log_message("Streamlit ì•± ì‹¤í–‰ ìš”ì²­ ì™„ë£Œ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰).")
        print("[INFO] Streamlit ëŒ€ì‹œë³´ë“œê°€ ìƒˆ ì°½ì´ë‚˜ íƒ­ì—ì„œ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤.")
    except FileNotFoundError:
        log_message("[ERROR] Streamlitì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print("[ERROR] Streamlitì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `pip install streamlit`ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        log_message(f"[ERROR] Streamlit ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"[ERROR] Streamlit ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    log_message("ìŠ¤í¬ë¦½íŠ¸ì˜ __main__ ì§„ì…ì  ì‹¤í–‰ë¨")
    # argparseëŠ” ì´ë¯¸ ìœ„ì— import ë˜ì–´ ìˆìŒ

    parser = argparse.ArgumentParser(description="Run the full analysis pipeline for video and prompt, then launch Streamlit dashboard.")
    parser.add_argument("--prompt", required=True, help="Path to the prompt text file.")
    parser.add_argument("--video", required=True, help="Path to the video file.")
    parser.add_argument("--model", default="yolov8m.pt", help="Path to the YOLO model (e.g., yolov8m.pt).")
    
    args = parser.parse_args()
    log_message(f"ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì íŒŒì‹± ì™„ë£Œ. Args: prompt='{args.prompt}', video='{args.video}', model='{args.model}'")

    try:
        run_pipeline(args.prompt, args.video, model_path=args.model)
        log_message("run_pipeline í•¨ìˆ˜ ì‹¤í–‰ ì™„ë£Œ (ë©”ì¸ ë¸”ë¡)")
    except Exception as e:
        log_message(f"run_pipeline í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ (ë©”ì¸ ë¸”ë¡): {e}")
        print(f"[CRITICAL ERROR] íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") # ì‚¬ìš©ìì—ê²Œ ë³´ì´ëŠ” ì¤‘ìš” ì˜¤ë¥˜ ë©”ì‹œì§€
        # ê°œë°œ ì¤‘ì—ëŠ” ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ë¥¼ ë³´ëŠ” ê²ƒì´ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # raise